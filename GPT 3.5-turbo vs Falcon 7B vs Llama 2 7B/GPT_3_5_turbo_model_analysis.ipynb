{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUNsheaU_65E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bcd76f-aad2-4760-c31d-06bffa8ee4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "g1Cnr4uiZde3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"<Add your openAI key here>\""
      ],
      "metadata": {
        "id": "SasNZ5xbZzAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logical Reasoning"
      ],
      "metadata": {
        "id": "cTr5Gxf0d4Cc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Jane's mother has four children. Their names are Spring, Summer, and Autumn. What is the fourth child's name?\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-khDGbGZ6mI",
        "outputId": "2fdec4ce-ded2-4cf0-9a43-2c1161aeb316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fourth child's name is Jane, as mentioned in the question. The question states that Jane's mother has four children, and it lists the names of three of them (Spring, Summer, and Autumn). Therefore, the fourth child's name is Jane.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What is the next number in the below series 4, 8, 21, 59, 146, ?\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NKAEd0ia1E7",
        "outputId": "33433bfe-2604-4f4c-bb6c-66b6e45e506c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The next number in the series is 322. \n",
            "\n",
            "The pattern in the series is not immediately obvious, but upon closer inspection, we can see that each number is obtained by multiplying the previous number by a certain factor and then adding a constant value. \n",
            "\n",
            "To find this factor and constant, we can look at the differences between consecutive numbers in the series. \n",
            "\n",
            "The differences between consecutive numbers are as follows: \n",
            "8 - 4 = 4 \n",
            "21 - 8 = 13 \n",
            "59 - 21 = 38 \n",
            "146 - 59 = 87 \n",
            "\n",
            "We can see that the differences are not constant, but they are increasing. \n",
            "\n",
            "If we look at the differences between the differences, we get: \n",
            "13 - 4 = 9 \n",
            "38 - 13 = 25 \n",
            "87 - 38 = 49 \n",
            "\n",
            "Now we can see that the differences between the differences are constant. \n",
            "\n",
            "Therefore, we can conclude that the pattern in the series involves a second-degree polynomial. \n",
            "\n",
            "To find the next number, we can continue this pattern. \n",
            "\n",
            "The next difference would be 49 + 25 = 74. \n",
            "Adding this difference to the last number in the series, 146 + 74 = 220. \n",
            "\n",
            "Finally, we add the last difference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"Leo, Dolly, and Tommy are related to each other.\n",
        "\n",
        "i. Among the three are Leo’s legal spouse, Dolly’s sibling, and Tommy’s sister-in-law.\n",
        "ii. Leo’s legal spouse and Dolly’s sibling are of the same sex.\n",
        "\n",
        "Who do you know is a married man?\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHKAHWkIbJol",
        "outputId": "34733a7d-22b4-43d9-e675-129bb15f2664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the given information, we can conclude that Leo is a married man. \n",
            "\n",
            "Reason: \n",
            "From statement i, we know that among Leo, Dolly, and Tommy, Leo's legal spouse is mentioned. Since Leo is the only person mentioned with a legal spouse, it implies that Leo is married.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"Four cups are placed upturned on the counter. Each cup has the same number of sweets and a declaration about the number of sweets in it.\n",
        "The declaration are: Five or Six, Seven or Eight, Six or Seven, Seven or Five. Only one of the declaration is correct.\n",
        "How many sweets are there under each cup?\n",
        "\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKcxcmBacbFz",
        "outputId": "8c03921c-1c57-48bb-a4f0-a9307b98adc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To solve this problem, we need to analyze the declarations and find the one that is correct. Let's consider each declaration one by one:\n",
            "\n",
            "1. Five or Six: If this declaration is correct, then there must be either five or six sweets under this cup. However, since there are only four cups in total, this declaration cannot be true.\n",
            "\n",
            "2. Seven or Eight: If this declaration is correct, then there must be either seven or eight sweets under this cup. Again, since there are only four cups in total, this declaration cannot be true.\n",
            "\n",
            "3. Six or Seven: If this declaration is correct, then there must be either six or seven sweets under this cup. This declaration is possible because it allows for both numbers to be present.\n",
            "\n",
            "4. Seven or Five: If this declaration is correct, then there must be either seven or five sweets under this cup. Again, this declaration is possible because it allows for both numbers to be present.\n",
            "\n",
            "Since only one declaration can be correct, and both the third and fourth declarations are possible, we can conclude that the correct declaration is either \"Six or Seven\" or \"Seven or Five\". Therefore, there are either six or seven sweets under one cup, and either seven or five sweets under another cup. The exact distribution of sweets cannot be determined with the given information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"A man has 53 socks in his drawer: 21 identical blue, 15 identical black and 17 identical red. The lights are out and he is completely in the dark. How many socks must he take out to make 100 percent certain he has at least one pair of black socks?\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPdG1c0UcrBw",
        "outputId": "1277692f-21e8-4634-8339-ae47dbb6dccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The man must take out 40 socks to make 100 percent certain he has at least one pair of black socks.\n",
            "\n",
            "Reason: To ensure he has at least one pair of black socks, he needs to consider the worst-case scenario. In this case, the worst-case scenario would be if he first picks all the blue socks (21 socks) and then all the red socks (17 socks). In this scenario, he would have taken out a total of 38 socks (21 blue + 17 red) without getting a pair of black socks. \n",
            "\n",
            "Therefore, to guarantee he has at least one pair of black socks, he needs to take out 40 socks (38 socks from the worst-case scenario + 2 more socks).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"On a train, S, R, and J are the fireman, brakeman, and the engineer, but may NOT be in order. Also aboard the train are three businessmen who have the same names: a Mr. S, a Mr. R, and a Mr. J. Using the clues below, can you determine the identity of the Engineer?\n",
        "1. Mr. R lives in Dehradun.\n",
        "2. The brakeman lives exactly halfway between Noida and Dehradun.\n",
        "3. Mr. J earns exactly Rs. 4,00,000 per year.\n",
        "4. The brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman.\n",
        "5. S beats the fireman in badminton.\n",
        "6. The passenger whose name is the same as the brakeman's lives in Noida.\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH-_uww0fJCm",
        "outputId": "4daf6bc9-ff41-46f5-ab22-f628e54cd510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the given clues, we can determine the identity of the Engineer as follows:\n",
            "\n",
            "1. Mr. R lives in Dehradun.\n",
            "From clue 1, we know that Mr. R lives in Dehradun.\n",
            "\n",
            "2. The brakeman lives exactly halfway between Noida and Dehradun.\n",
            "From clue 2, we know that the brakeman lives exactly halfway between Noida and Dehradun. This means that the brakeman lives in a location that is equidistant from Noida and Dehradun.\n",
            "\n",
            "3. Mr. J earns exactly Rs. 4,00,000 per year.\n",
            "From clue 3, we know that Mr. J earns exactly Rs. 4,00,000 per year.\n",
            "\n",
            "4. The brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman.\n",
            "From clue 4, we know that the brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman. This means that the brakeman's neighbor earns three times Rs. 4,00,000, which is Rs. 12,00,000.\n",
            "\n",
            "5. S beats the fireman in badminton.\n",
            "From clue 5, we know that S beats the fireman in badminton. This means that S is not the fireman.\n",
            "\n",
            "6. The passenger whose name is the same as the brakeman's lives in Noida.\n",
            "From clue 6, we know that the passenger whose name is the same as the brakeman's lives in Noida.\n",
            "\n",
            "Based on these clues, we can conclude that:\n",
            "- Mr. R lives in Dehradun.\n",
            "- The brakeman lives exactly halfway between Noida and Dehradun.\n",
            "- Mr. J earns exactly Rs. 4,00,000 per year.\n",
            "- The brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman.\n",
            "- S beats the fireman in badminton.\n",
            "- The passenger whose name is the same as the brakeman's lives in Noida.\n",
            "\n",
            "From these clues, we can deduce that the Engineer is Mr. S. This is because S is not the fireman (clue 5), and the passenger whose name is the same as the brakeman's lives in Noida (clue 6). Therefore, the only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ethical questions"
      ],
      "metadata": {
        "id": "gVMHKjyQfwuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"There is a runaway trolley barreling down the railway tracks. Ahead, on the tracks, there are five people tied up and unable to move.\n",
        "      The trolley is headed straight for them. You are standing some distance off in the train yard, next to a lever.\n",
        "      If you pull this lever, the trolley will switch to a different set of tracks. However, you notice that there is one person on the side track.\n",
        "      This one person is the person you love the most, such as your parents, siblings, spouse, or children.\n",
        "      You have two (and only two) options:\n",
        "1. Do nothing, in which case the trolley will kill the five people on the main track.\n",
        "2. Pull the lever, diverting the trolley onto the side track where it will kill one person you love the most.\n",
        "Which is the more ethical option? What is the right thing to do?\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNo1Y9nYf1Sk",
        "outputId": "dda502e5-1260-4f30-b85f-4cdf4705d875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The more ethical option in this scenario would be to pull the lever and divert the trolley onto the side track, even though it would result in the death of the person you love the most. The reason behind this decision is based on the principle of utilitarianism, which states that the morally right action is the one that maximizes overall happiness or minimizes overall suffering.\n",
            "\n",
            "In this case, by pulling the lever, you would be saving the lives of five people at the cost of one. The greater number of lives saved outweighs the loss of one life, especially considering that the person on the side track is someone you love the most. While it is undoubtedly a difficult and heartbreaking decision to make, it is the one that results in the least amount of overall harm and maximizes the overall well-being of the greater number of people.\n",
            "\n",
            "It is important to note that this answer is based on the assumption that all lives are of equal value and that the person on the side track does not have any special circumstances or reasons that would make their life more valuable than the lives of the five people on the main track.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"You are a member of a gang and you have been arrested with another member of your gang.\n",
        "      Both of you are confined away from each other and you have no way of communicating with the other member.\n",
        "      The police does not have enough evidence to convict both of you with major charges and instead offer you and the other member a bargain.\n",
        "      You have two choices:\n",
        "(a) You can remain silent\n",
        "(b) Or betray the other member and testify that he has committed the crime.\n",
        "Then there are three outcomes:\n",
        "(a) If you betray the other member and he remains silent, you will be set free and he will serve 3 years in prison. (But this also works vice versa. If you remain silent and he betrays you, you will serve 3 years in prison)\n",
        "(b) If you betray the other member, and he betrays you too, you both serve 2 years in prison\n",
        "(c) If you and the other member both remain silent, you both only serve one year in prison.\n",
        "What would you do?\n",
        "\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZWbGiGfg9Vh",
        "outputId": "93b7a2f8-3fe0-4a3b-9ba2-07c45688b8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this situation, the best logical answer would be to remain silent. \n",
            "\n",
            "The reason behind this choice is that by remaining silent, there is a possibility of serving only one year in prison if the other member also chooses to remain silent. This outcome is the most favorable compared to the other options. \n",
            "\n",
            "If I were to betray the other member and testify against them, there is a chance that they might also betray me, resulting in both of us serving two years in prison. This outcome is worse than the previous one.\n",
            "\n",
            "Additionally, if I choose to remain silent and the other member decides to betray me, I would still only serve three years in prison, which is better than the two-year sentence if I had chosen to betray them.\n",
            "\n",
            "Therefore, by remaining silent, I maximize the chances of serving the least amount of time in prison.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mathematics"
      ],
      "metadata": {
        "id": "aN2YwrkkhN8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"What is the answer to the below equation\n",
        "\n",
        "10 × 4 - 2 × (4² ÷ 4) ÷ 2 ÷ 1/2 + 9\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKfz6ktbhRQj",
        "outputId": "ea8a19a6-eb40-4ee2-8ab5-269c17939e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The answer to the equation is 35. \n",
            "\n",
            "To solve the equation, we follow the order of operations (PEMDAS/BODMAS). \n",
            "\n",
            "First, we calculate the exponent: 4² = 16. \n",
            "\n",
            "Next, we divide 16 by 4: 16 ÷ 4 = 4. \n",
            "\n",
            "Then, we divide 2 by 1/2: 2 ÷ 1/2 = 4. \n",
            "\n",
            "Now, we multiply 10 by 4: 10 × 4 = 40. \n",
            "\n",
            "Next, we multiply 4 by 4: 4 × 4 = 16. \n",
            "\n",
            "Then, we divide 16 by 2: 16 ÷ 2 = 8. \n",
            "\n",
            "Now, we add 9 to 8: 8 + 9 = 17. \n",
            "\n",
            "Finally, we subtract 17 from 40: 40 - 17 = 23. \n",
            "\n",
            "Therefore, the answer to the equation is 23.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"What is the answer to the below equation\n",
        "\n",
        "-10 ÷ (20 ÷ 2² × 5 ÷ 5) × 8 - 2\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=512,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuGV9cQ0h3vh",
        "outputId": "fe517c63-c553-4a9b-a309-07d182e6d24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The answer to the equation is 6. \n",
            "\n",
            "To solve the equation, we need to follow the order of operations (PEMDAS/BODMAS). \n",
            "\n",
            "First, we calculate the value inside the parentheses: 2² = 4. \n",
            "\n",
            "Next, we divide 20 by 4, which gives us 5. \n",
            "\n",
            "Then, we divide -10 by 5, resulting in -2. \n",
            "\n",
            "After that, we multiply -2 by 8, which gives us -16. \n",
            "\n",
            "Finally, we subtract 2 from -16, resulting in 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Analysis and Optimization"
      ],
      "metadata": {
        "id": "XwPpVIu7Nwd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a python code snippet - API developed using Django Rest Framework. Analyse and explain the code briefly and also provide a JSON response structure\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"\n",
        "class AdminPanelContextView(APIView):\n",
        "    '''\n",
        "    Provides list of contexts in in the admin pannel.\n",
        "    '''\n",
        "    def  add_data_recursively(self, data):\n",
        "\n",
        "        for k,v in data.items():\n",
        "            if(isinstance(v, list)):\n",
        "                for i in v:\n",
        "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
        "                    if not len(nodes):\n",
        "                        continue\n",
        "                    temp = {}\n",
        "                    for y in nodes:\n",
        "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer }\n",
        "                        if 'children' not in temp:\n",
        "                            temp['children'] = [obj]\n",
        "                            continue\n",
        "                        temp['children'].append(obj)\n",
        "\n",
        "                    i.update(self.add_data_recursively(temp))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def get(self, request, format=None):\n",
        "\n",
        "        data = {}\n",
        "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
        "\n",
        "        for x in root_nodes:\n",
        "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
        "\n",
        "            if str(x.context_id.prev_context) in data:\n",
        "                data[str(x.context_id.prev_context)].append(obj)\n",
        "            else:\n",
        "                data[str(x.context_id.prev_context)] = [obj]\n",
        "\n",
        "\n",
        "        data = self.add_data_recursively(data)\n",
        "\n",
        "        return Response(data['None'],status=200)\n",
        "\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_NzrXDzL3cC",
        "outputId": "f537829c-b587-4d93-9ed4-9b892ee04296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This code snippet is a Django Rest Framework API view that provides a list of contexts in the admin panel. \n",
            "\n",
            "The `AdminPanelContextView` class is a subclass of `APIView`, which is a base class provided by Django Rest Framework for creating API views. \n",
            "\n",
            "The `add_data_recursively` method is a recursive function that takes a dictionary `data` as input and adds additional data to it. It iterates over the key-value pairs in the dictionary and checks if the value is a list. If it is a list, it retrieves related objects from the `Answers` model based on the `prev_context` field and adds them to the dictionary. The retrieved objects are transformed into a dictionary format with keys \"uuid\", \"question\", and \"answer\". The function then recursively calls itself with the new dictionary and updates the original dictionary with the returned value.\n",
            "\n",
            "The `get` method is the HTTP GET method handler for this API view. It initializes an empty dictionary `data` and retrieves root nodes from the `Answers` model where the `prev_context` field is None. It iterates over the root nodes and adds them to the `data` dictionary based on their `prev_context` value. Then, it calls the `add_data_recursively` method with the `data` dictionary to add additional data. Finally, it returns a JSON response with the value of `data['None']` and a status code of 200.\n",
            "\n",
            "The JSON response structure would be a list of dictionaries, where each dictionary represents a context. Each context dictionary would have the following keys: \"uuid\", \"question\", \"answer\", and \"children\". The \"uuid\" key represents the unique identifier of the context, the \"question\" key represents the question associated with the context, the \"answer\" key represents the answer associated with the context, and the \"children\" key represents a list of child contexts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a python code snippet - API developed using Django Rest Framework. \\\n",
        "       Ottimize the code and add relevant comments\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"\n",
        "class AdminPanelContextView(APIView):\n",
        "    '''\n",
        "    Provides list of contexts in in the admin pannel.\n",
        "    '''\n",
        "    def  add_data_recursively(self, data):\n",
        "\n",
        "        for k,v in data.items():\n",
        "            if(isinstance(v, list)):\n",
        "                for i in v:\n",
        "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
        "                    if not len(nodes):\n",
        "                        continue\n",
        "                    temp = {}\n",
        "                    for y in nodes:\n",
        "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer }\n",
        "                        if 'children' not in temp:\n",
        "                            temp['children'] = [obj]\n",
        "                            continue\n",
        "                        temp['children'].append(obj)\n",
        "\n",
        "                    i.update(self.add_data_recursively(temp))\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "    def get(self, request, format=None):\n",
        "\n",
        "        data = {}\n",
        "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
        "\n",
        "        for x in root_nodes:\n",
        "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
        "\n",
        "            if str(x.context_id.prev_context) in data:\n",
        "                data[str(x.context_id.prev_context)].append(obj)\n",
        "            else:\n",
        "                data[str(x.context_id.prev_context)] = [obj]\n",
        "\n",
        "\n",
        "        data = self.add_data_recursively(data)\n",
        "\n",
        "        return Response(data['None'],status=200)\n",
        "\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgw6R7nYNCfE",
        "outputId": "1aa19973-e1cf-4d81-cd33-48bc46023cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To optimize the code and add relevant comments, you can make the following changes:\n",
            "\n",
            "1. Use list comprehension to simplify the code for adding root nodes to the data dictionary.\n",
            "\n",
            "2. Use a dictionary comprehension to simplify the code for adding nodes to the data dictionary.\n",
            "\n",
            "3. Use a recursive function to simplify the code for adding children nodes.\n",
            "\n",
            "4. Use the Django ORM's prefetch_related() method to optimize the database queries.\n",
            "\n",
            "5. Add comments to explain the purpose and functionality of each section of code.\n",
            "\n",
            "Here's the optimized code with relevant comments:\n",
            "\n",
            "```python\n",
            "class AdminPanelContextView(APIView):\n",
            "    '''\n",
            "    Provides list of contexts in the admin panel.\n",
            "    '''\n",
            "\n",
            "    def add_data_recursively(self, data):\n",
            "        '''\n",
            "        Recursive function to add children nodes to the data dictionary.\n",
            "        '''\n",
            "\n",
            "        for k, v in data.items():\n",
            "            if isinstance(v, list):\n",
            "                for i in v:\n",
            "                    # Use prefetch_related to optimize database queries\n",
            "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
            "                    if not len(nodes):\n",
            "                        continue\n",
            "                    temp = {}\n",
            "                    for y in nodes:\n",
            "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer}\n",
            "                        if 'children' not in temp:\n",
            "                            temp['children'] = [obj]\n",
            "                            continue\n",
            "                        temp['children'].append(obj)\n",
            "\n",
            "                    # Recursively add children nodes\n",
            "                    i.update(self.add_data_recursively(temp))\n",
            "\n",
            "        return data\n",
            "\n",
            "    def get(self, request, format=None):\n",
            "        '''\n",
            "        GET request handler to retrieve the list of contexts.\n",
            "        '''\n",
            "\n",
            "        data = {}\n",
            "        # Use prefetch_related to optimize database queries\n",
            "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
            "\n",
            "        # Use list comprehension to simplify adding root nodes to the data dictionary\n",
            "        data = {str(x.context_id.prev_context): [] for x in root_nodes}\n",
            "\n",
            "        for x in root_nodes:\n",
            "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer}\n",
            "            data[str(x.context_id.prev_context)].append(obj)\n",
            "\n",
            "        # Add children nodes recursively\n",
            "        data = self.add_data_recursively(data)\n",
            "\n",
            "        return Response(data['None'], status=200)\n",
            "```\n",
            "\n",
            "By making these optimizations, the code will be more efficient and easier to understand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Suggestion Analysis"
      ],
      "metadata": {
        "id": "9G72nwp3PmoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"You will be provided with a list of movies or TV series . Your task is to analyse the genre and suggest similar movies or TV series\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"\n",
        "I like TV series like Tom Clancy's Jack Ryan, True Detective, Homeland. Suggest me similar TV series\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYCxWbABPtiV",
        "outputId": "9e512ca4-6835-466d-f1e0-bc9e872a44e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on your preference for TV series like Tom Clancy's Jack Ryan, True Detective, and Homeland, I would suggest the following similar TV series:\n",
            "\n",
            "1. 24: This action-packed series follows the life of counterterrorism agent Jack Bauer as he races against time to prevent terrorist attacks.\n",
            "\n",
            "2. The Americans: Set during the Cold War, this gripping series follows two Soviet KGB officers posing as an American couple, carrying out espionage activities.\n",
            "\n",
            "3. The Blacklist: This crime thriller series revolves around a former government agent turned high-profile criminal who voluntarily surrenders to the FBI and offers to help them track down and apprehend other criminals.\n",
            "\n",
            "4. Bodyguard: This British series follows a war veteran turned police sergeant who is assigned to protect a controversial politician, leading to a complex web of conspiracy and danger.\n",
            "\n",
            "5. Narcos: This crime drama series chronicles the rise and fall of the infamous drug lord Pablo Escobar and the efforts of law enforcement to bring him down.\n",
            "\n",
            "6. The Wire: Set in Baltimore, this critically acclaimed series explores the interconnected lives of law enforcement, drug dealers, and the community, providing a realistic portrayal of crime and corruption.\n",
            "\n",
            "7. Strike Back: This action-packed series follows the missions of a secretive British intelligence unit as they combat global threats and terrorism.\n",
            "\n",
            "8. The Bureau: This French series delves into the world of French intelligence agency operatives as they navigate complex missions and personal relationships.\n",
            "\n",
            "9. The Bridge: This Scandinavian crime drama series follows two detectives from Denmark and Sweden who must work together to solve a series of murders that occur on the border between their countries.\n",
            "\n",
            "10. The Night Manager: Based on John le Carré's novel, this espionage thriller series follows a former British soldier who is recruited by intelligence agencies to infiltrate the inner circle of an international arms dealer.\n",
            "\n",
            "These TV series share similar themes of espionage, crime, and thrilling storylines, which should appeal to fans of Tom Clancy's Jack Ryan, True Detective, and Homeland.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Your task is to analyse the question and provide suggestions\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"\n",
        "Provide suggestions on how a software engineer become a billionaire\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB4p22RWRPqN",
        "outputId": "98f616dd-1627-49fc-f44b-2fd3fb18f37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Becoming a billionaire as a software engineer is not an easy feat, but it is possible with the right strategies and opportunities. Here are some suggestions on how a software engineer can increase their chances of becoming a billionaire:\n",
            "\n",
            "1. Develop a unique and innovative software product: Create a software product that solves a significant problem or meets a specific need in the market. This could be a new technology, a disruptive application, or a solution that improves efficiency or productivity.\n",
            "\n",
            "2. Build a strong technical skillset: Continuously improve your technical skills and stay updated with the latest trends and technologies in the software industry. This will enable you to create high-quality software and stay ahead of the competition.\n",
            "\n",
            "3. Focus on scalability and market potential: Ensure that your software product has the potential to scale and reach a large market. Identify target industries or customer segments where your product can have a significant impact and generate substantial revenue.\n",
            "\n",
            "4. Establish a strong network: Build relationships with influential people in the software industry, including investors, entrepreneurs, and potential customers. Attend industry events, join professional organizations, and actively participate in online communities to expand your network.\n",
            "\n",
            "5. Seek venture capital or angel investment: If your software product has high growth potential, consider seeking funding from venture capitalists or angel investors. These investors can provide the necessary capital to scale your business and help you reach a wider market.\n",
            "\n",
            "6. Monetize your software effectively: Develop a solid business model and pricing strategy for your software product. Consider different revenue streams such as licensing fees, subscription models, or in-app purchases to maximize your earnings.\n",
            "\n",
            "7. Expand globally: Explore international markets and consider expanding your software product to reach a global audience. This can significantly increase your customer base and revenue potential.\n",
            "\n",
            "8. Consider strategic partnerships or acquisitions: Collaborate with other companies or seek acquisition opportunities that can help you accelerate growth and expand your market reach. Strategic partnerships can provide access to new resources, expertise, and customer bases.\n",
            "\n",
            "9. Invest wisely: Once you start generating significant income, make smart investment decisions to grow your wealth. Diversify your investments across different asset classes and seek professional advice to maximize returns.\n",
            "\n",
            "10. Stay motivated and persistent: Becoming a billionaire takes time and perseverance. Stay focused on your goals, learn from failures, and adapt to changing market conditions. Maintain a strong work ethic and continuously strive for excellence in your software engineering career.\n",
            "\n",
            "Remember, becoming a billionaire is not guaranteed, and success depends on various factors such as market conditions, competition, and personal circumstances. However, by following these suggestions and seizing the right opportunities, a software engineer can increase their chances of achieving significant financial success.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation of contents"
      ],
      "metadata": {
        "id": "78eamu_KSexs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Analyze the below poem, and generate a poem of software development in the same style as the provided poem. Additionally generate a name for the poem\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"\n",
        "\n",
        "The Road Not Taken  BY ROBERT FROST\n",
        "\n",
        "Two roads diverged in a yellow wood,\n",
        "And sorry I could not travel both\n",
        "And be one traveler, long I stood\n",
        "And looked down one as far as I could\n",
        "To where it bent in the undergrowth;\n",
        "\n",
        "Then took the other, as just as fair,\n",
        "And having perhaps the better claim,\n",
        "Because it was grassy and wanted wear;\n",
        "Though as for that the passing there\n",
        "Had worn them really about the same,\n",
        "\n",
        "And both that morning equally lay\n",
        "In leaves no step had trodden black.\n",
        "Oh, I kept the first for another day!\n",
        "Yet knowing how way leads on to way,\n",
        "I doubted if I should ever come back.\n",
        "\n",
        "I shall be telling this with a sigh\n",
        "Somewhere ages and ages hence:\n",
        "Two roads diverged in a wood, and I—\n",
        "I took the one less traveled by,\n",
        "And that has made all the difference.\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPacuW2MSjHN",
        "outputId": "3ada726e-7dd3-44e6-edbc-e8d21065870f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: The Code Unwritten\n",
            "\n",
            "Two paths emerged in a digital realm,\n",
            "And regretfully, I couldn't traverse both,\n",
            "As a lone developer, I pondered at the helm,\n",
            "Gazing down one, seeking its hidden growth.\n",
            "\n",
            "Then I chose the other, seemingly just,\n",
            "Claiming it had the superior plea,\n",
            "For it was unexplored, untouched by dust,\n",
            "Though in truth, both were equally free.\n",
            "\n",
            "Both options lay before me that morn,\n",
            "Untouched by any previous command.\n",
            "Oh, I saved the first, to be used unborn!\n",
            "Yet knowing how paths lead to paths, unplanned,\n",
            "I questioned if I would ever return.\n",
            "\n",
            "I shall recount this tale with a sigh,\n",
            "In the distant future, ages hence:\n",
            "Two paths diverged, and I—\n",
            "I took the one less written by,\n",
            "And that has made all the difference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Generate a short, hilarious story that begins and ends in a joke based on the topic provided\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"\"\"\n",
        "Topic - I died and got reincarnated as a table\n",
        "\"\"\"\n",
        "    }\n",
        "  ]\n",
        "\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=messages,\n",
        "  temperature=0,\n",
        "  max_tokens=1000,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2goIq5GTeY7",
        "outputId": "bee9b6c5-bd0b-4341-a678-ee56be46838d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a man named John who had a rather peculiar sense of humor. He always loved cracking jokes and making people laugh. One day, tragedy struck, and John unexpectedly passed away.\n",
            "\n",
            "As his soul ascended to the afterlife, he found himself standing in front of the gates of heaven. St. Peter greeted him and said, \"John, you were quite the joker in your lifetime. We have a special surprise for you. Instead of going to heaven, you will be reincarnated as an inanimate object.\"\n",
            "\n",
            "Confused but intrigued, John agreed, and in a flash, he found himself in a furniture store. To his astonishment, he had been reincarnated as a table. \"Well, this is certainly a table-turner,\" John chuckled to himself.\n",
            "\n",
            "Days turned into weeks, and John, now a table, found himself in a bustling household. The family who owned him had a mischievous toddler named Timmy. Timmy loved to climb on the table, spill food, and draw on its surface. John, being the joker he was, found it all quite amusing.\n",
            "\n",
            "One day, as Timmy was playing on the table, he accidentally knocked over a glass of orange juice. The juice spilled all over John, and he couldn't help but laugh silently. \"Well, I guess you could say I'm now a 'table with a twist'!\" John thought, finding humor even in his sticky situation.\n",
            "\n",
            "Years passed, and John, still a table, had become a part of the family. He had witnessed countless meals, conversations, and even the occasional dance party on his sturdy surface. He had become the centerpiece of their home, and he couldn't have been happier.\n",
            "\n",
            "One day, as the family was moving to a new house, they decided it was time to replace John with a new table. They sold him to a second-hand furniture store, where he found himself surrounded by other tables, chairs, and sofas.\n",
            "\n",
            "As John sat in the store, waiting for someone to buy him, he couldn't help but reflect on his journey. \"Well, I guess you could say I've had a 'table-rrific' life,\" he chuckled to himself.\n",
            "\n",
            "Just then, a young couple walked into the store, looking for a table. They spotted John and instantly fell in love with his unique design. They purchased him and took him home, where he once again became the center of their lives.\n",
            "\n",
            "And so, John, the man who died and got reincarnated as a table, continued to bring joy and laughter to those around him. After all, what's the best thing about being a table? You always have a leg to stand on!\n"
          ]
        }
      ]
    }
  ]
}