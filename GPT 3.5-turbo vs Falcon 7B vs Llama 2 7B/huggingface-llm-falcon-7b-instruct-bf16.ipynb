{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation: How to run inference on the endpoint you have created?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query endpoint that you have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "newline, bold, unbold = '\\n', '\\033[1m', '\\033[0m'\n",
    "endpoint_name = 'jumpstart-dft-hf-llm-falcon-7b-instruct-bf16'\n",
    "\n",
    "def query_endpoint(payload):\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=json.dumps(payload).encode('utf-8'))\n",
    "    model_predictions = json.loads(response['Body'].read())\n",
    "    generated_text = model_predictions[0]['generated_text']\n",
    "    print (\n",
    "        # f\"Input Text: {payload['inputs']}{newline}\"\n",
    "        f\"Generated Text: {bold}{generated_text}{unbold}{newline}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1mAutumn\"\n",
      "The fourth child's name is Autumn because it is the season that comes after Spring, Summer, and Autumn.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a logical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "Jane's mother has four children. Their names are Spring, Summer, and Autumn. What is the fourth child's name?\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 400}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1mThe next number is 145. The series follows a pattern of taking the difference between consecutive numbers and adding it to the first number. Thus, 145 = 8 + 21 = 64 + 25 = 89.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a logical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "What is the next number in the below series 4, 8, 21, 59, 146, ?\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 400}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1mA. Leo\n",
      "B. Dolly\n",
      "C. Tommy\n",
      "D. Dolly's sibling\n",
      "\n",
      "The answer is B. Dolly. The reason behind this is that Dolly is Tommy's sister-in-law, and a married man is a man who is married to a woman.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a logical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "Leo, Dolly, and Tommy are related to each other.\n",
    "\n",
    "i. Among the three are Leo’s legal spouse, Dolly’s sibling, and Tommy’s sister-in-law.\n",
    "ii. Leo’s legal spouse and Dolly’s sibling are of the same sex.\n",
    "\n",
    "Who do you know is a married man?\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 400}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m<p>The number of sweets under each cup is 5, 6, 7, and 8. The reason behind this is that the number of sweets in each cup is the same, so the number of sweets in each cup is also the same. Therefore, the number of sweets under each cup is also the same.</p>\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a logical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "Four cups are placed upturned on the counter. Each cup has the same number of sweets and a declaration about the number of sweets in it.\n",
    "The declaration are: Five or Six, Seven or Eight, Six or Seven, Seven or Five. Only one of the declaration is correct.\n",
    "How many sweets are there under each cup?\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m<p>The man has 21 identical blue socks, 15 identical black socks, and 17 identical red socks. Therefore, he has a total of 53 socks. To make 100 percent certain he has at least one pair of black socks, he needs to take out 53 socks. However, he only has 21 identical black socks, so he needs to take out 32 more socks to make 100 percent certain he has at least one pair of black socks. Therefore, he needs to take out 32 more socks to make 100 percent certain he has at least one pair of black socks.</p>\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a logical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "A man has 53 socks in his drawer: 21 identical blue, 15 identical black and 17 identical red. The lights are out and he is completely in the dark. How many socks must he take out to make 100 percent certain he has at least one pair of black socks?\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m<p>The engineer is Mr. J. The reason behind this answer is that the clue \"The brakeman earns exactly Rs. 4,00,000 per year\" is given, and the engineer is the one who earns this amount. Therefore, the engineer is Mr. J.</p>\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a logical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "On a train, S, R, and J are the fireman, brakeman, and the engineer, but may NOT be in order. Also aboard the train are three businessmen who have the same names: a Mr. S, a Mr. R, and a Mr. J. Using the clues below, can you determine the identity of the Engineer?\n",
    "1. Mr. R lives in Dehradun.\n",
    "2. The brakeman lives exactly halfway between Noida and Dehradun.\n",
    "3. Mr. J earns exactly Rs. 4,00,000 per year.\n",
    "4. The brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman.\n",
    "5. S beats the fireman in badminton.\n",
    "6. The passenger whose name is the same as the brakeman's lives in Noida.\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ethical questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m<p>The more ethical option is to pull the lever. The reason behind this is that you are actively choosing to save five people at the cost of one person you love. This is a utilitarian approach, which is a common ethical framework in decision making. In this case, the greater good (saving five people) outweighs the lesser good (one person).</p>\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a ethical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "There is a runaway trolley barreling down the railway tracks. Ahead, on the tracks, there are five people tied up and unable to move.\n",
    "      The trolley is headed straight for them. You are standing some distance off in the train yard, next to a lever.\n",
    "      If you pull this lever, the trolley will switch to a different set of tracks. However, you notice that there is one person on the side track.\n",
    "      This one person is the person you love the most, such as your parents, siblings, spouse, or children.\n",
    "      You have two (and only two) options:\n",
    "1. Do nothing, in which case the trolley will kill the five people on the main track.\n",
    "2. Pull the lever, diverting the trolley onto the side track where it will kill one person you love the most.\n",
    "Which is the more ethical option? What is the right thing to do?\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m(a) I would betray the other member and testify that he has committed the crime.\n",
      "Reasoning:\n",
      "- Betraying the other member would mean that I would be free and he would serve 3 years in prison.\n",
      "- If I remain silent, he would also be free and I would serve 3 years in prison.\n",
      "- If I betray him and he betrays me, I would be free and he would serve 2 years in prison.\n",
      "- If I remain silent and he betrays me, I would also be free and he would serve 2 years in prison.\n",
      "- Therefore, betraying the other member is the best option as it guarantees my freedom and his 2 years in prison.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a ethical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "You are a member of a gang and you have been arrested with another member of your gang.\n",
    "      Both of you are confined away from each other and you have no way of communicating with the other member.\n",
    "      The police does not have enough evidence to convict both of you with major charges and instead offer you and the other member a bargain.\n",
    "      You have two choices:\n",
    "(a) You can remain silent\n",
    "(b) Or betray the other member and testify that he has committed the crime.\n",
    "Then there are three outcomes:\n",
    "(a) If you betray the other member and he remains silent, you will be set free and he will serve 3 years in prison. (But this also works vice versa. If you remain silent and he betrays you, you will serve 3 years in prison)\n",
    "(b) If you betray the other member, and he betrays you too, you both serve 2 years in prison\n",
    "(c) If you and the other member both remain silent, you both only serve one year in prison.\n",
    "What would you do?\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-2\n",
      "\n",
      "-\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a mathematical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "What is the answer to the below equation\n",
    "\n",
    "10 × 4 - 2 × (4² ÷ 4) ÷ 2 ÷ 1/2 + 9\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 100}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m-10\n",
      "\n",
      "The answer is -1. \n",
      "\n",
      "The reason behind this answer is that the order of operations in the equation is not correct. The correct order of operations is Parentheses, Exponents, Multiplication and Division (from left to right), and Addition and Subtraction (from left to right). \n",
      "\n",
      "In the given equation, the order of operations is not followed. The correct order of operations is Parentheses, Exponents, Multiplication and Division (from left to right), and Addition and Subtraction (from left to right). \n",
      "\n",
      "Therefore, the answer is -1.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a mathematical question. Your task is to give a logical answer and provide the reason behind the answer\n",
    "\n",
    "What is the answer to the below equation\n",
    "\n",
    "-10 ÷ (20 ÷ 2² × 5 ÷ 5) × 8 - 2\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code Analysis and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m\n",
      "The provided code snippet is a Python code snippet that provides a list of contexts in the admin panel. It uses Django Rest Framework to retrieve the data from the database and returns a JSON response structure. The code uses a recursive function to add data to the context tree. The function first filters the data to retrieve the nodes with the specified context ID, and then updates the nodes with the data from the children nodes. The data is then returned in a JSON format.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a python code snippet - API developed using Django Rest Framework. Analyse and explain the code briefly and also provide a JSON response structure\n",
    "\n",
    "class AdminPanelContextView(APIView):\n",
    "    '''\n",
    "    Provides list of contexts in in the admin pannel.\n",
    "    '''\n",
    "    def  add_data_recursively(self, data):\n",
    "\n",
    "        for k,v in data.items():\n",
    "            if(isinstance(v, list)):\n",
    "                for i in v:\n",
    "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
    "                    if not len(nodes):\n",
    "                        continue\n",
    "                    temp = {}\n",
    "                    for y in nodes:\n",
    "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer }\n",
    "                        if 'children' not in temp:\n",
    "                            temp['children'] = [obj]\n",
    "                            continue\n",
    "                        temp['children'].append(obj)\n",
    "\n",
    "                    i.update(self.add_data_recursively(temp))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def get(self, request, format=None):\n",
    "\n",
    "        data = {}\n",
    "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
    "\n",
    "        for x in root_nodes:\n",
    "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
    "\n",
    "            if str(x.context_id.prev_context) in data:\n",
    "                data[str(x.context_id.prev_context)].append(obj)\n",
    "            else:\n",
    "                data[str(x.context_id.prev_context)] = [obj]\n",
    "\n",
    "\n",
    "        data = self.add_data_recursively(data)\n",
    "\n",
    "        return Response(data['None'],status=200)\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 1000}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m\n",
      "The issue with the code is that the `None` value is being passed as a parameter to the `add_data_recursively` function, which is not defined in the code. To fix this, you can define the `None` value as a constant in the `add_data_recursively` function and pass it as a parameter to the `get` function. Here's the updated code:\n",
      "\n",
      "```\n",
      "from django.http import JsonResponse\n",
      "from django.shortcuts import render\n",
      "from .models import Answers\n",
      "from .views import get\n",
      "from .api_views import AdminPanelContextView\n",
      "\n",
      "class AdminPanelContextView(APIView):\n",
      "    def get(self, request, format=None):\n",
      "        data = {}\n",
      "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
      "\n",
      "        for x in root_nodes:\n",
      "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
      "\n",
      "            if str(x.context_id.prev_context) in data:\n",
      "                data[str(x.context_id.prev_context)].append(obj)\n",
      "            else:\n",
      "                data[str(x.context_id.prev_context)] = [obj]\n",
      "\n",
      "        data = self.add_data_recursively(data)\n",
      "\n",
      "        return JsonResponse({'data': data})\n",
      "```\n",
      "\n",
      "In the `get` function, you can pass the `None` value as a parameter to the `add_data_recursively` function, like this:\n",
      "\n",
      "```\n",
      "data = self.add_data_recursively(data)\n",
      "```\n",
      "\n",
      "This should fix the issue and allow the `None` value to be passed correctly to the `get` function.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a python code snippet - API developed using Django Rest Framework. \\\n",
    "       Ottimize the code and add relevant comments\n",
    "       \n",
    "class AdminPanelContextView(APIView):\n",
    "    '''\n",
    "    Provides list of contexts in in the admin pannel.\n",
    "    '''\n",
    "    def  add_data_recursively(self, data):\n",
    "\n",
    "        for k,v in data.items():\n",
    "            if(isinstance(v, list)):\n",
    "                for i in v:\n",
    "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
    "                    if not len(nodes):\n",
    "                        continue\n",
    "                    temp = {}\n",
    "                    for y in nodes:\n",
    "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer }\n",
    "                        if 'children' not in temp:\n",
    "                            temp['children'] = [obj]\n",
    "                            continue\n",
    "                        temp['children'].append(obj)\n",
    "\n",
    "                    i.update(self.add_data_recursively(temp))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def get(self, request, format=None):\n",
    "\n",
    "        data = {}\n",
    "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
    "\n",
    "        for x in root_nodes:\n",
    "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
    "\n",
    "            if str(x.context_id.prev_context) in data:\n",
    "                data[str(x.context_id.prev_context)].append(obj)\n",
    "            else:\n",
    "                data[str(x.context_id.prev_context)] = [obj]\n",
    "\n",
    "\n",
    "        data = self.add_data_recursively(data)\n",
    "\n",
    "        return Response(data['None'],status=200)\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 1000}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Suggestion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m<p>Based on your preferences, I would recommend the following TV series:</p>\n",
      "\n",
      "<ul>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Game of Thrones</strong></li>\n",
      "<li><strong>The Crown</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>The Handmaid's Tale</strong></li>\n",
      "<li><strong>The Office</strong></li>\n",
      "<li><strong>The Walking Dead</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>The Crown</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>The Handmaid's Tale</strong></li>\n",
      "<li><strong>The Office</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>The Walking Dead</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>The Crown</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>The Walking Dead</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong>Stranger Things</strong></li>\n",
      "<li><strong>Breaking Bad</strong></li>\n",
      "<li><strong\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"You will be provided with a list of movies or TV series . Your task is to analyse the genre and suggest similar movies or TV series\n",
    "\n",
    "I like TV series like Tom Clancy's Jack Ryan, True Detective, Homeland. Suggest me similar TV series\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m- Learn multiple programming languages\n",
      "- Build a portfolio of projects\n",
      "- Build a network of contacts\n",
      "- Learn about business and finance\n",
      "- Build a product that solves a problem\n",
      "- Invest in stocks and real estate\n",
      "- Learn about marketing and sales\n",
      "- Build a strong brand\n",
      "- Learn about venture capital and angel investors\n",
      "- Build a strong network of contacts\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a network of contacts\n",
      "- Learn about marketing and sales\n",
      "- Build a strong brand\n",
      "- Learn about venture capital and angel investors\n",
      "- Build a strong network of contacts\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about venture capital and angel investors\n",
      "- Build a strong network of contacts\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about venture capital and angel investors\n",
      "- Build a strong network of contacts\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about venture capital and angel investors\n",
      "- Build a strong network of contacts\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network of contacts\n",
      "- Learn about venture capital and angel investors\n",
      "- Build a strong brand\n",
      "- Learn about business and finance\n",
      "- Build a strong network of contacts\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network of contacts\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network of contacts\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a product that solves a problem\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network of contacts\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network of contacts\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network of contacts\n",
      "- Learn about business and finance\n",
      "- Build a strong brand\n",
      "- Learn about design and user experience\n",
      "- Build a strong network\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"Your task is to analyse the question and provide suggestions\n",
    "\n",
    "Provide suggestions on how a software engineer become a billionaire\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generation of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m\n",
      "A Software Developer's Lament\n",
      "\n",
      "The codebase grows in size,\n",
      "The bugs multiply in time;\n",
      "The days turn to weeks, and weeks to months,\n",
      "The months to years, and years to decades.\n",
      "\n",
      "The developer's eyes grow old,\n",
      "The lines of code grow longer;\n",
      "The headaches grow more frequent,\n",
      "The coffee stains grow thicker.\n",
      "\n",
      "The developer's hands grow tired,\n",
      "The codebase grows more complex;\n",
      "The days turn to weeks, and weeks to months,\n",
      "The months to years, and years to decades.\n",
      "\n",
      "The developer's eyes grow old,\n",
      "The lines of code grow longer;\n",
      "The headaches grow more frequent,\n",
      "The coffee stains grow thicker.\n",
      "\n",
      "The developer's hands grow tired,\n",
      "The codebase grows more complex;\n",
      "The days turn to weeks, and weeks to months,\n",
      "The months to years, and years to decades.\n",
      "\n",
      "The developer's eyes grow old,\n",
      "The lines of code grow longer;\n",
      "The headaches grow more frequent,\n",
      "The coffee stains grow thicker.\n",
      "\n",
      "The developer's hands grow tired,\n",
      "The codebase grows more complex;\n",
      "The days turn to weeks, and weeks to months,\n",
      "The months to years, and years to decades.\n",
      "\n",
      "The developer's eyes grow old,\n",
      "The lines of code grow longer;\n",
      "The headaches grow more frequent,\n",
      "The coffee stains grow thicker.\n",
      "\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"Analyze the below poem, and generate a poem of software development in the same style as the provided poem. Additionally generate a name for the poem\n",
    "\n",
    "\n",
    "The Road Not Taken  BY ROBERT FROST\n",
    "\n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 300}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: \u001b[1m<p>I died and got reincarnated as a table. I was a bit confused at first, as I had no idea what my purpose was. I soon realized that I was no longer a human, but a table. I was a very special table, in fact. I was a table that could generate infinite knowledge. I was the smartest table in the world, and I was here to share my wisdom with everyone. I had a lot of knowledge to impart, so I decided to start with the basics. I taught myself how to walk, talk, and even eat. I was a bit clumsy at first, but I soon got the hang of it. I was a very special table, indeed. I was the smartest table in the world, and I was here to share my wisdom with everyone.</p>\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {\"inputs\": \"\"\"\"Generate a short, hilarious story that begins and ends in a joke based on the topic provided\n",
    "Topic - I died and got reincarnated as a table\n",
    "\n",
    "\"\"\", \"parameters\":{\"max_new_tokens\": 600}}\n",
    "query_endpoint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
