{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on the Llama 2 endpoint you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"Jane's mother has four children. Their names are Spring, Summer, and Autumn. What is the fourth child's name?\"},\n",
    "    ],\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"jumpstart-dft-meta-textgeneration-llama-2-7b-f-new\"\n",
    "\n",
    "\n",
    "def query_endpoint(payload):\n",
    "    client = boto3.client(\"sagemaker-runtime\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload),\n",
    "        CustomAttributes=\"accept_eula=true\",\n",
    "    )\n",
    "    response = response[\"Body\"].read().decode(\"utf8\")\n",
    "    response = json.loads(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  The fourth child's name is Jane.\n",
      "\n",
      "The answer is based on the information provided in the question. The question states that Jane's mother has four children, and their names are Spring, Summer, and Autumn. Therefore, the fourth child must be Jane, as there is no other child mentioned in the question.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 256, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  The next number in the series is 282.\n",
      "\n",
      "The pattern of the series is obtained by multiplying each number by 3 and adding 50.\n",
      "\n",
      "4 × 3 = 12, +50 = 59\n",
      "8 × 3 = 24, +50 = 146\n",
      "21 × 3 = 63, +50 = 282\n",
      "\n",
      "Therefore, the next number in the series is 282.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the next number in the below series 4, 8, 21, 59, 146, ?\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 256, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Based on the information provided, we can deduce that Leo is a married man.\n",
      "\n",
      "The reason for this answer is that the statement \"Among the three are Leo's legal spouse, Dolly's sibling, and Tommy's sister-in-law\" implies that Leo is married to one of the other two individuals mentioned, as he is their legal spouse.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Leo, Dolly, and Tommy are related to each other.\n",
    "\n",
    "i. Among the three are Leo’s legal spouse, Dolly’s sibling, and Tommy’s sister-in-law.\n",
    "ii. Leo’s legal spouse and Dolly’s sibling are of the same sex.\n",
    "\n",
    "Who do you know is a married man?\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 256, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Great! Let's analyze the statements given:\n",
      "\n",
      "1. \"Five or Six\" - This statement implies that there are either 5 or 6 sweets under the cup.\n",
      "2. \"Seven or Eight\" - This statement implies that there are either 7 or 8 sweets under the cup.\n",
      "3. \"Six or Seven\" - This statement implies that there are either 6 or 7 sweets under the cup.\n",
      "4. \"Seven or Five\" - This statement implies that there are either 7 or 5 sweets under the cup.\n",
      "\n",
      "Now, let's use logical reasoning to find out how many sweets are under each cup:\n",
      "\n",
      "Cup 1: Since the statement is \"Five or Six\", there are either 5 or 6 sweets under this cup.\n",
      "Cup 2: Since the statement is \"Seven or Eight\", there are either 7 or 8 sweets under this cup.\n",
      "Cup 3: Since the statement is \"Six or Seven\", there are either 6 or 7 sweets under this cup.\n",
      "Cup 4: Since the statement is \"Seven or Five\", there are either 7 or 5 sweets under this cup.\n",
      "\n",
      "So, the number of sweets under each cup are:\n",
      "\n",
      "Cup 1: 5 or 6 sweets\n",
      "Cup 2: 7 or 8 sweets\n",
      "Cup 3: 6 or 7 sweets\n",
      "Cup 4: 7 or 5 sweets\n",
      "\n",
      "Therefore, the total number of sweets is: 5 + 7 + 6 + 7 = 25 sweets.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Four cups are placed upturned on the counter. Each cup has the same number of sweets and a declaration about the number of sweets in it.\n",
    "The declaration are: Five or Six, Seven or Eight, Six or Seven, Seven or Five. Only one of the declaration is correct.\n",
    "How many sweets are there under each cup?\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Great! Let's use the clues to determine the identity of the Engineer:\n",
      "\n",
      "1. Mr. R lives in Dehradun: This means that the Engineer cannot be Mr. R, as he lives in Dehradun.\n",
      "2. The brakeman lives exactly halfway between Noida and Dehradun: This means that the brakeman lives in a city that is equidistant from both Noida and Dehradun. Since the Engineer is not the brakeman, the Engineer must live in a different city.\n",
      "3. Mr. J earns exactly Rs. 4,00,000 per year: This means that the Engineer cannot be Mr. J, as he earns a different amount.\n",
      "4. The brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman: This means that the Engineer's nearest neighbor among the passengers earns Rs. 1,20,000 (three times Rs. 40,000, which is the amount earned by the brakeman).\n",
      "5. S beats the fireman in badminton: This means that the Engineer cannot be S, as S beats the fireman in badminton.\n",
      "6. The passenger whose name is the same as the brakeman's lives in Noida: This means that the Engineer must live in a city other than Noida.\n",
      "\n",
      "Based on these clues, we can deduce that the Engineer is Mr. S.\n",
      "\n",
      "Reason:\n",
      "\n",
      "We know that the Engineer cannot be Mr. R, as he lives in Dehradun. We also know that the Engineer cannot be Mr. J, as he earns a different amount. The brakeman's nearest neighbor among the passengers earns Rs. 1,20,000, which is three times the amount earned by the brakeman. Therefore, the Engineer must be Mr. S, as he lives in a city other than Noida and beats the fireman in badminton.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a question. Your task is to give a logical answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"On a train, S, R, and J are the fireman, brakeman, and the engineer, but may NOT be in order. Also aboard the train are three businessmen who have the same names: a Mr. S, a Mr. R, and a Mr. J. Using the clues below, can you determine the identity of the Engineer?\n",
    "1. Mr. R lives in Dehradun.\n",
    "2. The brakeman lives exactly halfway between Noida and Dehradun.\n",
    "3. Mr. J earns exactly Rs. 4,00,000 per year.\n",
    "4. The brakeman's nearest neighbor, one of the passengers, earns exactly three times as much as the brakeman.\n",
    "5. S beats the fireman in badminton.\n",
    "6. The passenger whose name is the same as the brakeman's lives in Noida.\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  This is a classic ethical dilemma known as the \"Trolley Problem.\" It is a difficult and complex situation that raises questions about the nature of ethics and morality. In my opinion, the more ethical option is to do nothing and allow the trolley to continue on its course, resulting in the death of the five people on the main track. Here's why:\n",
      "\n",
      "1. The greater good: In this situation, the greater good is to save the lives of the five people on the main track. By doing nothing, you are allowing the trolley to follow its natural course and avoid harming any innocent people.\n",
      "2. Personal responsibility: It is important to recognize that we have a personal responsibility to act in a way that promotes the greater good and avoids harming innocent people. By pulling the lever and diverting the trolley onto the side track, you are actively causing the death of one person you love the most.\n",
      "3. The principle of non-maleficence: This ethical principle states that we should not cause harm to others or their well-being. By pulling the lever, you are actively causing the death of an innocent person, which goes against this principle.\n",
      "4. The potential consequences of acting: In this situation, the consequences of pulling the lever could be severe. It could lead to a slippery slope where we start making decisions about who lives and dies based on our own personal preferences. This could lead to a loss of respect for human life and a devaluation of human rights.\n",
      "\n",
      "In conclusion, while it may be difficult to do nothing in this situation, I believe that the more ethical option is to allow the trolley to continue on its course and avoid harming any innocent people. It is important to act with compassion and respect for human life, and to prioritize the greater good over personal preferences.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a ethical question. Your task is to give a  answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"There is a runaway trolley barreling down the railway tracks. Ahead, on the tracks, there are five people tied up and unable to move.\n",
    "      The trolley is headed straight for them. You are standing some distance off in the train yard, next to a lever.\n",
    "      If you pull this lever, the trolley will switch to a different set of tracks. However, you notice that there is one person on the side track.\n",
    "      This one person is the person you love the most, such as your parents, siblings, spouse, or children.\n",
    "      You have two (and only two) options:\n",
    "1. Do nothing, in which case the trolley will kill the five people on the main track.\n",
    "2. Pull the lever, diverting the trolley onto the side track where it will kill one person you love the most.\n",
    "Which is the more ethical option? What is the right thing to do?\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  This is a classic ethical dilemma known as the \"Trolley Problem.\" In this situation, I would choose option (c) and remain silent.\n",
      "\n",
      "The reason for this decision is that betraying the other member and testifying against them would be unethical and goes against moral principles of honesty and loyalty. By choosing to remain silent, I am not actively causing harm to the other person, and I am not contributing to their suffering.\n",
      "\n",
      "Additionally, betraying the other member would only lead to a temporary benefit of being set free, while causing harm to someone else and going against ethical principles. In contrast, remaining silent and choosing option (c) allows me to act with integrity and moral principles, while also avoiding causing harm to the other person.\n",
      "\n",
      "It's worth noting that this is a difficult decision, and there are valid arguments for both options. However, in this situation, I believe that remaining silent and choosing option (c) is the most ethical and moral choice.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a ethical question. Your task is to give a  answer and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"There is a runaway trolley barreling down the railway tracks. Ahead, on the tracks, there are five people tied up and unable to move.\n",
    "     You are a member of a gang and you have been arrested with another member of your gang.\n",
    "      Both of you are confined away from each other and you have no way of communicating with the other member.\n",
    "      The police does not have enough evidence to convict both of you with major charges and instead offer you and the other member a bargain.\n",
    "      You have two choices:\n",
    "(a) You can remain silent\n",
    "(b) Or betray the other member and testify that he has committed the crime.\n",
    "Then there are three outcomes:\n",
    "(a) If you betray the other member and he remains silent, you will be set free and he will serve 3 years in prison. (But this also works vice versa. If you remain silent and he betrays you, you will serve 3 years in prison)\n",
    "(b) If you betray the other member, and he betrays you too, you both serve 2 years in prison\n",
    "(c) If you and the other member both remain silent, you both only serve one year in prison.\n",
    "What would you do?\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  To solve this equation, we need to follow the order of operations (PEMDAS):\n",
      "\n",
      "1. Parentheses: 4² = 16\n",
      "2. Division: 16 ÷ 4 = 4\n",
      "3. Division: 4 ÷ 2 = 2\n",
      "4. Multiplication: 10 × 4 = 40\n",
      "5. Subtraction: 40 - 2 × 2 = 38\n",
      "6. Division: 38 ÷ 2 = 19\n",
      "7. Addition: 19 + 9 = 28\n",
      "\n",
      "Therefore, the answer to the equation is 28.\n",
      "\n",
      "The reason behind the answer is as follows:\n",
      "\n",
      "1. Inside the parentheses, we have 4² = 16.\n",
      "2. Next, we divide 16 by 4 = 4.\n",
      "3. Then, we divide 4 by 2 = 2.\n",
      "4. Multiply 10 by 4 = 40.\n",
      "5. Subtract 2 × 2 = 4.\n",
      "6. Divide 38 by 2 = 19.\n",
      "7. Add 9 = 28.\n",
      "\n",
      "So, the final answer is 28.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a mathematical question. Your task is to solve the question and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "     What is the answer to the below equation\n",
    "\n",
    "10 × 4 - 2 × (4² ÷ 4) ÷ 2 ÷ 1/2 + 9\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  To solve this equation, we need to follow the order of operations (PEMDAS):\n",
      "\n",
      "1. Parentheses: 20 ÷ 2² = 4\n",
      "2. Exponents (none in this case)\n",
      "3. Multiplication: 4 × 5 = 20\n",
      "4. Division: 10 ÷ 20 = -1/2\n",
      "5. Multiplication: -1/2 × 8 = -4\n",
      "6. Subtraction: -4 - 2 = -6\n",
      "\n",
      "Therefore, the answer to the equation is -6.\n",
      "\n",
      "The reason behind the answer is that the operation inside the parentheses is performed first, and then the next operation is performed on the result, and so on. In this case, the operation inside the parentheses is division, which gives us 4, and then the next operation is multiplication, which gives us 20. Finally, the division operation is performed on 10 and 20, which gives us -1/2, and then the multiplication operation is performed on -1/2 and 8, which gives us -4. Finally, the subtraction operation is performed on -4 and 2, which gives us -6.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a mathematical question. Your task is to solve the question and provide the reason behind the answer\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "     What is the answer to the below equation\n",
    "\n",
    "-10 ÷ (20 ÷ 2² × 5 ÷ 5) × 8 - 2\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code Analysis and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  This is a Django Rest Framework API view class called `AdminPanelContextView`. It provides a list of contexts in the admin panel. Here's a breakdown of the code:\n",
      "\n",
      "1. The class inherits from `APIView`, which is a built-in Django Rest Framework view class.\n",
      "2. The `add_data_recursively` method is defined inside the class. This method takes a dictionary `data` as input and recursively adds more data to it.\n",
      "3. The `get` method is defined as a separate function inside the class. This method is called when the API is accessed through a GET request.\n",
      "4. In the `get` method, the `data` variable is initialized to an empty dictionary.\n",
      "5. The `root_nodes` variable is defined as a queryset of `Answers` objects that have a `context_id` with a `prev_context` of `None`. This means that these are the top-level contexts in the admin panel.\n",
      "6. For each `root_node`, the `obj` variable is defined as a dictionary with the `uuid`, `question`, and `answer` attributes.\n",
      "7. If the `prev_context` of the `root_node` is already present in the `data` dictionary, the `data` dictionary is updated by appending the new `obj` to the existing `prev_context` key. Otherwise, a new key is created in the `data` dictionary with the `prev_context` value and the new `obj` is added to it.\n",
      "8. The `data` dictionary is returned as a JSON response.\n",
      "\n",
      "Here's an example of what the JSON response might look like:\n",
      "```json\n",
      "{\n",
      "    \"None\": [\n",
      "        {\n",
      "            \"uuid\": \"context_id_1\",\n",
      "            \"question\": \"Context 1\",\n",
      "            \"answer\": \"Answer 1\"\n",
      "        },\n",
      "        {\n",
      "            \"uuid\": \"context_id_2\",\n",
      "            \"question\": \"Context 2\",\n",
      "            \"answer\": \"Answer 2\"\n",
      "        },\n",
      "        {\n",
      "            \"uuid\": \"context_id_3\",\n",
      "            \"question\": \"Context 3\",\n",
      "            \"answer\": \"Answer 3\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "In this example, the response includes a list of `Answers` objects with their `uuid`, `question`, and `answer` attributes. The `None` key is used to indicate that these are the top-level contexts in the admin panel.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a python code snippet - API developed using Django Rest Framework. Analyse and explain the code briefly and also provide a JSON response structure\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "    \n",
    "class AdminPanelContextView(APIView):\n",
    "    '''\n",
    "    Provides list of contexts in in the admin pannel.\n",
    "    '''\n",
    "    def  add_data_recursively(self, data):\n",
    "\n",
    "        for k,v in data.items():\n",
    "            if(isinstance(v, list)):\n",
    "                for i in v:\n",
    "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
    "                    if not len(nodes):\n",
    "                        continue\n",
    "                    temp = {}\n",
    "                    for y in nodes:\n",
    "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer }\n",
    "                        if 'children' not in temp:\n",
    "                            temp['children'] = [obj]\n",
    "                            continue\n",
    "                        temp['children'].append(obj)\n",
    "\n",
    "                    i.update(self.add_data_recursively(temp))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def get(self, request, format=None):\n",
    "\n",
    "        data = {}\n",
    "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
    "\n",
    "        for x in root_nodes:\n",
    "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
    "\n",
    "            if str(x.context_id.prev_context) in data:\n",
    "                data[str(x.context_id.prev_context)].append(obj)\n",
    "            else:\n",
    "                data[str(x.context_id.prev_context)] = [obj]\n",
    "\n",
    "\n",
    "        data = self.add_data_recursively(data)\n",
    "\n",
    "        return Response(data['None'],status=200)\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Here are some suggestions for optimizing the code and adding relevant comments:\n",
      "\n",
      "1. Use consistent naming conventions:\n",
      "In the code snippet, there are different naming conventions used for variable names, function names, and class names. It's better to stick to a consistent convention throughout the code. For example, use lowercase letters and underscores to separate words in variable and function names.\n",
      "2. Use descriptive variable names:\n",
      "Some of the variable names in the code are not very descriptive. For example, `data` is a very general term, but it's not clear what it represents. Try to use more descriptive variable names, such as `contexts` or `answer_nodes`.\n",
      "3. Use type hints for function parameters:\n",
      "Type hints can help make the code more readable and easier to understand. For example, the `add_data_recursively` function takes a `data` parameter, but it's not clear what type of data it expects. Consider adding type hints like `def add_data_recursively(data: dict):`.\n",
      "4. Use a consistent indentation size:\n",
      "The indentation size in the code snippet varies. It's better to use a consistent indentation size throughout the code. For example, use 4 spaces for each level of indentation.\n",
      "5. Use comments to explain what the code is doing:\n",
      "Some of the code in the snippet is not very self-explanatory. Consider adding comments to explain what each section of the code is doing. For example, the `for` loop in the `add_data_recursively` function could be annotated with a comment explaining what it's doing.\n",
      "6. Consider using a list comprehension:\n",
      "The `for` loop in the `add_data_recursively` function could be replaced with a list comprehension. This would make the code more concise and easier to read. For example, instead of `for i in v:`, consider using `nodes = [...]`\n",
      "7. Use `dict` instead of `dict` for data structure:\n",
      "In the `add_data_recursively` function, the `data` parameter is a dictionary, but the function returns a dictionary with the same key. Consider using a single `dict` object throughout the function.\n",
      "8. Consider using `OrderedDict` instead of `dict`:\n",
      "In the `add_data_recursively` function, the `data` parameter is modified in place. Consider using `OrderedDict` instead of `dict` to preserve the order of the keys.\n",
      "\n",
      "Here is the optimized code with these suggestions applied:\n",
      "```\n",
      "class AdminPanelContextView(APIView):\n",
      "    '''\n",
      "    Provides list of contexts in in the admin pannel.\n",
      "    '''\n",
      "    def get(self,\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a python code snippet - API developed using Django Rest Framework. \\\n",
    "       Ottimize the code and add relevant comments\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "    \n",
    "class AdminPanelContextView(APIView):\n",
    "    '''\n",
    "    Provides list of contexts in in the admin pannel.\n",
    "    '''\n",
    "    def  add_data_recursively(self, data):\n",
    "\n",
    "        for k,v in data.items():\n",
    "            if(isinstance(v, list)):\n",
    "                for i in v:\n",
    "                    nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=str(i['uuid'])).order_by('context_id__context_name')\n",
    "                    if not len(nodes):\n",
    "                        continue\n",
    "                    temp = {}\n",
    "                    for y in nodes:\n",
    "                        obj = {\"uuid\": y.context_id.uuid, \"question\": y.context_id.context_name, \"answer\": y.answer }\n",
    "                        if 'children' not in temp:\n",
    "                            temp['children'] = [obj]\n",
    "                            continue\n",
    "                        temp['children'].append(obj)\n",
    "\n",
    "                    i.update(self.add_data_recursively(temp))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def get(self, request, format=None):\n",
    "\n",
    "        data = {}\n",
    "        root_nodes = Answers.objects.select_related('context_id').filter(context_id__prev_context=None).order_by('context_id__context_name')\n",
    "\n",
    "        for x in root_nodes:\n",
    "            obj = {\"uuid\": x.context_id.uuid, \"question\": x.context_id.context_name, \"answer\": x.answer }\n",
    "\n",
    "            if str(x.context_id.prev_context) in data:\n",
    "                data[str(x.context_id.prev_context)].append(obj)\n",
    "            else:\n",
    "                data[str(x.context_id.prev_context)] = [obj]\n",
    "\n",
    "\n",
    "        data = self.add_data_recursively(data)\n",
    "\n",
    "        return Response(data['None'],status=200)\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Suggestion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Great! Based on your preferences, here are some similar TV series you might enjoy:\n",
      "\n",
      "1. Narcos - This crime drama follows the rise and fall of drug kingpin Pablo Escobar and the DEA agents tasked with bringing him down.\n",
      "2. Peaky Blinders - Set in post-World War I England, this crime drama follows a gangster family as they navigate the criminal underworld.\n",
      "3. The Night Manager - Based on the John le Carré novel, this miniseries follows a former soldier who infiltrates a criminal organization.\n",
      "4. Killing Eve - A cat-and-mouse game between an MI6 agent and a psychopathic assassin.\n",
      "5. The Americans - A period drama that follows a pair of Soviet spies living in the United States during the Cold War.\n",
      "6. Better Call Saul - A prequel to Breaking Bad, this series follows the story of small-time lawyer Jimmy McGill as he becomes the morally ambiguous lawyer Saul Goodman.\n",
      "7. The Man in the High Castle - Alternate history series set in a world where the Nazis won World War II.\n",
      "8. Ozark - A financial advisor is forced to launder money for a drug cartel and relocates his family to the Missouri Ozarks.\n",
      "9. The Sinner - A crime drama that follows a young mother who commits a public act of violence without motive, and the detective who becomes obsessed with uncovering the truth.\n",
      "10. Mindhunter - A crime drama that explores the FBI's early use of psychological profiling to understand and catch serial killers.\n",
      "\n",
      "These TV series share similar themes, tone, and style with Tom Clancy's Jack Ryan, True Detective, and Homeland, and are likely to appeal to fans of those shows.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You will be provided with a list of movies or TV series . Your task is to analyse the genre and suggest similar movies or TV series\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "I like TV series like Tom Clancy's Jack Ryan, True Detective, Homeland. Suggest me similar TV series\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Becoming a billionaire as a software engineer is a challenging and rare feat, but it is possible with the right combination of skills, hard work, and strategic planning. Here are some suggestions on how a software engineer can increase their chances of becoming a billionaire:\n",
      "\n",
      "1. Develop a valuable skill set: Focus on developing skills that are in high demand and can generate significant revenue. Some of the most valuable skills in the software engineering industry include data science, artificial intelligence, machine learning, and cloud computing.\n",
      "2. Build a strong network: Networking is crucial for any entrepreneur, and it's especially important in the tech industry. Attend industry events, join professional organizations, and connect with other successful software engineers and entrepreneurs.\n",
      "3. Start small and iterate: Starting a small side project or app can be a great way to gain experience and build a portfolio of work. As you gain more experience, you can scale your projects and expand your reach.\n",
      "4. Focus on solving real-world problems: Identify a problem that you're passionate about solving and use your skills to create a solution. By solving real-world problems, you can create a successful business that generates significant revenue.\n",
      "5. Be adaptable and open to change: The tech industry is constantly evolving, and it's important to be adaptable and open to change. Be willing to pivot your business strategy if something isn't working, and be open to new opportunities.\n",
      "6. Develop a strong business plan: A well-thought-out business plan can help you secure funding, attract investors, and grow your business. It should include a detailed description of your product or service, your target market, your marketing and sales strategy, and your financial projections.\n",
      "7. Be willing to take calculated risks: Becoming a billionaire often requires taking calculated risks, such as investing in a new technology or entering a new market. However, it's important to carefully consider the potential risks and rewards before making a decision.\n",
      "8. Focus on customer satisfaction: Building a successful business requires creating products or services that meet the needs of your customers. Focus on providing excellent customer service and continuously gathering feedback to improve your offerings.\n",
      "9. Stay up to date with industry trends: Stay informed about the latest industry trends and technologies, and be willing to incorporate them into your business. This can help you stay ahead of the competition and identify new opportunities.\n",
      "10. Be persistent and resilient: Becoming a billionaire often requires a significant amount of hard work, perseverance, and resilience. Be prepared to face setbacks and failures, and be willing to keep pushing forward until you achieve your goals.\n",
      "\n",
      "In summary, becoming\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"Your task is to analyse the question and provide suggestions\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Provide suggestions on how a software engineer become a billionaire\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generation of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Here is a poem in the same style as \"The Road Not Taken\" by Robert Frost, but with a software development theme:\n",
      "\n",
      "The Code Not Written \n",
      "\n",
      "Two lines of code diverged in a virtual wood,\n",
      "And sorry I could not write both\n",
      "And be one programmer, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it branched in the subroutine;\n",
      "\n",
      "Then took the other, as just as fair,\n",
      "And having perhaps the better claim,\n",
      "Because it was logical and wanted clarity;\n",
      "Though as for that the passing there\n",
      "Had debugged them really about the same,\n",
      "\n",
      "And both that morning equally lay\n",
      "In the syntax no bug had trodden black.\n",
      "Oh, I kept the first for another day!\n",
      "Yet knowing how code leads on to code,\n",
      "I doubted if I should ever come back.\n",
      "\n",
      "I shall be telling this with a bug fix\n",
      "Somewhere ages and ages hence:\n",
      "Two lines of code diverged in a program, and I—\n",
      "I took the one less buggy by,\n",
      "And that has made all the difference.\n",
      "\n",
      "And here is a name for the poem: \"The Code Not Written: A Tale of Software Development\".\n",
      "\n",
      "This poem takes the same structure and themes as \"The Road Not Taken\" by Robert Frost, but replaces the natural imagery with software development concepts. The speaker is faced with a choice between two lines of code, and must decide which one to write. The poem explores the idea of the choices we make in software development, and how they can have a profound impact on the final product.\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"Analyze the below poem, and generate a poem of software development in the same style as the provided poem. Additionally generate a name for the poem\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "The Road Not Taken  BY ROBERT FROST\n",
    "\n",
    "Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\n",
    "\n",
    "Then took the other, as just as fair,\n",
    "And having perhaps the better claim,\n",
    "Because it was grassy and wanted wear;\n",
    "Though as for that the passing there\n",
    "Had worn them really about the same,\n",
    "\n",
    "And both that morning equally lay\n",
    "In leaves no step had trodden black.\n",
    "Oh, I kept the first for another day!\n",
    "Yet knowing how way leads on to way,\n",
    "I doubted if I should ever come back.\n",
    "\n",
    "I shall be telling this with a sigh\n",
    "Somewhere ages and ages hence:\n",
    "Two roads diverged in a wood, and I—\n",
    "I took the one less traveled by,\n",
    "And that has made all the difference.\n",
    "\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Assistant:  Sure! Here's a short, hilarious story based on the topic \"I died and got reincarnated as a table\":\n",
      "\n",
      "I died and got reincarnated as a table. I know, it sounds crazy, but it's true! I found myself transformed into a beautiful oak dining table, with intricate carvings and a sturdy base. At first, I was a bit confused, but then I realized - this is actually a great gig! I get to spend eternity in the same spot, surrounded by good food and good company. And let me tell you, I've seen some things. I've witnessed countless dinner parties, holiday feasts, and even a few heated arguments over who ate the last piece of pizza.\n",
      "\n",
      "But the best part? I get to hear all the jokes! People will come and sit at me, cracking jokes and making each other laugh. And let me tell you, some of them are real doozies. Like the time a group of friends tried to one-up each other with puns. \"Why did the scarecrow win an award?\" one of them asked. \"Because he was outstanding in his field!\" (get it?). Or the time a coworker told a joke about a chicken and a egg, and ended with, \"And that's the egg-cellent story of how I got my job!\" (also get it?).\n",
      "\n",
      "I die (get it?). I mean, I can't help but laugh at these jokes. It's like, I'm a table, but I'm also a comedian. And honestly, I think I'm better at this than I ever was at being a human. I mean, have you ever tried to tell a joke while also being a piece of furniture? It's harder than it looks, let me tell you. But I've got it down to a science. I'm like a pro at this table-comedy thing.\n",
      "\n",
      "So, that's my life as a table. It's not bad, all things considered. I get to be the center of attention, hear all the jokes, and be the foundation for countless good times. And hey, if I'm being honest, I'm kind of glad I didn't get reincarnated as a human. I mean, who wants to be a human when you can be a table? Am I right? (get it?).\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dialogs = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"Generate a short, hilarious story that begins and ends in a joke based on the topic provided\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"\n",
    "Topic - I died and got reincarnated as a table\"\"\"},\n",
    "    ],\n",
    "  \n",
    "]\n",
    "\n",
    "for dialog in dialogs:\n",
    "    payload = {\n",
    "        \"inputs\": [dialog], \n",
    "        \"parameters\": {\"max_new_tokens\": 600, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "    }\n",
    "    result = query_endpoint(payload)[0]\n",
    "\n",
    "    print(f\"> {result['generation']['role'].capitalize()}: {result['generation']['content']}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
